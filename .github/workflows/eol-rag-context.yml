name: EOL RAG Context - Complete CI/CD

on:
  push:
    branches: [ main, develop, feat/*, fix/* ]
    paths:
      - 'packages/eol-rag-context/**'
      - '.github/workflows/eol-rag-context.yml'
      - '.github/actions/**'
      - '.github/scripts/**'
      - '.github/badges/**'
      - 'README.md'

env:
  PACKAGE_PATH: packages/eol-rag-context
  PYTHON_VERSION: '3.11'
  UNIT_COVERAGE_THRESHOLD: 80
  INTEGRATION_COVERAGE_THRESHOLD: 60
  REDIS_HOST: localhost
  REDIS_PORT: 6379

jobs:
  # =========================================
  # Pre-flight & Dependency Setup
  # =========================================
  setup:
    name: üîß Setup & Dependencies
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache.outputs.cache-key }}
      package-changed: ${{ steps.changes.outputs.package }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 2

    - name: Detect changes
      uses: dorny/paths-filter@v2
      id: changes
      with:
        filters: |
          package:
            - 'packages/eol-rag-context/**'
            - '.github/workflows/**'
            - '.github/actions/**'
            - '.github/scripts/**'

    - name: Validate project structure
      if: steps.changes.outputs.package == 'true'
      working-directory: ${{ env.PACKAGE_PATH }}
      run: |
        echo "üîç Validating project structure..."
        required_files=(
          "pyproject.toml"
          "src/eol/rag_context/__init__.py"
          "tests/conftest.py"
          "tests/integration/conftest.py"
          "pytest.ini"
        )
        for file in "${required_files[@]}"; do
          if [ ! -f "$file" ]; then
            echo "‚ùå Missing required file: $file"
            exit 1
          fi
        done
        echo "‚úÖ Project structure validation passed"

    - name: Set up Python
      if: steps.changes.outputs.package == 'true'
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Generate cache key
      if: steps.changes.outputs.package == 'true'
      id: cache
      run: |
        echo "cache-key=deps-${{ runner.os }}-py${{ env.PYTHON_VERSION }}-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml', '**/uv.lock') }}" >> $GITHUB_OUTPUT

    - name: Cache dependencies
      if: steps.changes.outputs.package == 'true'
      id: cache-deps
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/uv
          ~/.local/share/uv
          ~/.cache/huggingface
          ~/.cache/torch
          ${{ env.PACKAGE_PATH }}/.venv
        key: ${{ steps.cache.outputs.cache-key }}
        restore-keys: |
          deps-${{ runner.os }}-py${{ env.PYTHON_VERSION }}-

    - name: Install dependencies
      if: steps.changes.outputs.package == 'true' && steps.cache-deps.outputs.cache-hit != 'true'
      working-directory: ${{ env.PACKAGE_PATH }}
      run: |
        # Install uv for fast package management
        curl -LsSf https://astral.sh/uv/install.sh | sh
        export PATH="$HOME/.local/bin:$PATH"

        # Create virtual environment
        uv venv .venv

        # Install ALL dependencies for all test types at once
        uv pip install --python .venv/bin/python \
          pytest pytest-asyncio pytest-cov pytest-timeout pytest-xdist pytest-benchmark \
          redis redisvl sentence-transformers aioredis \
          watchdog gitignore-parser \
          black isort flake8 bandit safety \
          -r requirements.txt

        # Pre-download sentence transformer models
        .venv/bin/python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')" || true

        echo "‚úÖ Dependencies installed and cached"

  # =========================================
  # Code Quality Checks
  # =========================================
  quality:
    name: üìä Code Quality
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.package-changed == 'true'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Restore dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/uv
          ~/.local/share/uv
          ~/.cache/huggingface
          ~/.cache/torch
          ${{ env.PACKAGE_PATH }}/.venv
        key: ${{ needs.setup.outputs.cache-key }}

    - name: Run quality checks
      working-directory: ${{ env.PACKAGE_PATH }}
      run: |
        source .venv/bin/activate

        echo "üîç Code formatting (Black)..."
        black --check --diff src/ tests/

        echo "üîç Import sorting (isort)..."
        isort --check-only --diff src/ tests/

        echo "üîç Linting (flake8)..."
        flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,W503

        echo "üîç Security scan (bandit)..."
        bandit -r src/ -ll

        echo "üîç Dependency security (safety)..."
        safety check || true

  # =========================================
  # Unit Tests (Matrix)
  # =========================================
  unit-tests:
    name: üß™ Unit Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.package-changed == 'true'
    strategy:
      matrix:
        python-version: ['3.11', '3.12', '3.13']
      fail-fast: false

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/uv
          ~/.local/share/uv
          ~/.cache/huggingface
          ~/.cache/torch
          ${{ env.PACKAGE_PATH }}/.venv-${{ matrix.python-version }}
        key: deps-${{ runner.os }}-py${{ matrix.python-version }}-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml', '**/uv.lock') }}
        restore-keys: |
          deps-${{ runner.os }}-py${{ matrix.python-version }}-

    - name: Setup dependencies (ultra-fast)
      uses: ./.github/actions/setup-python-deps-ultra-fast
      with:
        python-version: ${{ matrix.python-version }}
        test-type: unit
        working-directory: ${{ env.PACKAGE_PATH }}

    - name: Run unit tests
      working-directory: ${{ env.PACKAGE_PATH }}
      env:
        PYTHONPATH: ${{ github.workspace }}/${{ env.PACKAGE_PATH }}/src
      run: |
        source .venv-${{ matrix.python-version }}/bin/activate

        python -m pytest tests/unit/ \
          -v --tb=short \
          -n auto --maxprocesses=4 \
          --cov=eol.rag_context \
          --cov-report=xml:unit-coverage-${{ matrix.python-version }}.xml \
          --cov-report=html:unit-coverage-${{ matrix.python-version }} \
          --junit-xml=unit-test-results-${{ matrix.python-version }}.xml \
          --timeout=300

    - name: Upload unit test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: unit-test-results-${{ matrix.python-version }}
        path: |
          ${{ env.PACKAGE_PATH }}/unit-test-results-${{ matrix.python-version }}.xml
          ${{ env.PACKAGE_PATH }}/unit-coverage-${{ matrix.python-version }}.xml

  # =========================================
  # Integration Tests
  # =========================================
  integration-tests:
    name: üîÑ Integration Tests
    runs-on: ubuntu-latest
    needs: [setup, unit-tests]
    if: needs.setup.outputs.package-changed == 'true'

    services:
      redis:
        image: redis/redis-stack:latest
        ports:
          - 6379:6379
          - 8001:8001
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 5s
          --health-timeout 3s
          --health-retries 10

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Setup dependencies (ultra-fast)
      uses: ./.github/actions/setup-python-deps-ultra-fast
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        test-type: integration
        working-directory: ${{ env.PACKAGE_PATH }}

    - name: Wait for Redis
      run: |
        echo "‚è≥ Waiting for Redis Stack..."
        timeout 30s bash -c 'until redis-cli -h localhost -p 6379 ping; do sleep 1; done'
        redis-cli -h localhost -p 6379 MODULE LIST | grep search || exit 1
        echo "‚úÖ Redis Stack ready"

    - name: Run integration tests
      working-directory: ${{ env.PACKAGE_PATH }}
      env:
        PYTHONPATH: ${{ github.workspace }}/${{ env.PACKAGE_PATH }}/src
      run: |
        source .venv-${{ env.PYTHON_VERSION }}/bin/activate

        # Clear Redis data
        redis-cli -h localhost -p 6379 FLUSHALL

        # Run integration tests
        python -m pytest tests/integration/ \
          -v --tb=short \
          -n auto --maxprocesses=4 \
          --cov=eol.rag_context --cov-append \
          --cov-report=xml:integration-coverage.xml \
          --cov-report=html:integration-coverage \
          --junit-xml=integration-test-results.xml \
          --timeout=300 \
          -m integration

    - name: Generate test summary
      if: always()
      working-directory: ${{ env.PACKAGE_PATH }}
      run: |
        python ${{ github.workspace }}/.github/scripts/test_summary.py \
          integration-test-results.xml \
          "Integration Tests" || true

    - name: Upload integration test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: integration-test-results
        path: |
          ${{ env.PACKAGE_PATH }}/integration-test-results.xml
          ${{ env.PACKAGE_PATH }}/integration-coverage.xml

  # =========================================
  # Performance Tests
  # =========================================
  performance-tests:
    name: ‚ö° Performance Tests
    runs-on: ubuntu-latest
    needs: [setup, integration-tests]
    if: needs.setup.outputs.package-changed == 'true'

    services:
      redis:
        image: redis/redis-stack:latest
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Setup dependencies (ultra-fast)
      uses: ./.github/actions/setup-python-deps-ultra-fast
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        test-type: performance
        working-directory: ${{ env.PACKAGE_PATH }}

    - name: Run performance tests
      working-directory: ${{ env.PACKAGE_PATH }}
      env:
        PYTHONPATH: ${{ github.workspace }}/${{ env.PACKAGE_PATH }}/src
      run: |
        source .venv-${{ env.PYTHON_VERSION }}/bin/activate

        python -m pytest tests/integration/test_full_workflow_integration.py::TestFullWorkflowIntegration::test_performance_metrics \
          -v --tb=short \
          --benchmark-json=performance-results.json \
          -m performance || true

    - name: Generate performance summary
      if: always()
      working-directory: ${{ env.PACKAGE_PATH }}
      run: |
        python ${{ github.workspace }}/.github/scripts/performance_summary.py \
          performance-results.json || echo "No performance results"

    - name: Upload performance results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: performance-results
        path: ${{ env.PACKAGE_PATH }}/performance-results.json

  # =========================================
  # Coverage Analysis - Separate Unit & Integration Metrics
  # =========================================
  coverage:
    name: üìà Coverage Analysis
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    if: always() && needs.setup.outputs.package-changed == 'true'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Download all test results
      uses: actions/download-artifact@v4
      with:
        pattern: '*-test-results*'
        path: test-results/
        merge-multiple: true

    - name: Install coverage tools
      run: |
        pip install coverage

    - name: Analyze unit test coverage
      working-directory: test-results
      run: |
        echo "üìä Analyzing unit test coverage..."

        # Find unit coverage files (from all Python versions)
        unit_files=($(find . -name 'unit-coverage-*.xml' 2>/dev/null))

        if [ ${#unit_files[@]} -gt 0 ]; then
          # Use the coverage from the primary Python version (3.11)
          if [ -f "unit-coverage-3.11.xml" ]; then
            cp unit-coverage-3.11.xml unit-coverage-final.xml
            echo "‚úÖ Using unit coverage from Python 3.11"
          else
            # Fallback to first available unit coverage
            cp "${unit_files[0]}" unit-coverage-final.xml
            echo "‚úÖ Using unit coverage from: ${unit_files[0]}"
          fi

          # Check unit coverage threshold
          echo "üéØ Checking unit test coverage against ${UNIT_COVERAGE_THRESHOLD}% threshold..."
          python ${{ github.workspace }}/.github/scripts/coverage_check.py \
            unit-coverage-final.xml \
            ${{ env.UNIT_COVERAGE_THRESHOLD }} \
            --badge unit-coverage-badge.json \
            --type "Unit Tests"
        else
          echo "‚ö†Ô∏è No unit coverage files found"
          echo '<?xml version="1.0" ?><coverage line-rate="0.0" lines-covered="0" lines-valid="1"/>' > unit-coverage-final.xml
        fi

    - name: Analyze integration test coverage
      working-directory: test-results
      run: |
        echo "üìä Analyzing integration test coverage..."

        if [ -f "integration-coverage.xml" ]; then
          cp integration-coverage.xml integration-coverage-final.xml
          echo "‚úÖ Using integration coverage"

          # Check integration coverage threshold
          echo "üéØ Checking integration test coverage against ${INTEGRATION_COVERAGE_THRESHOLD}% threshold..."
          python ${{ github.workspace }}/.github/scripts/coverage_check.py \
            integration-coverage-final.xml \
            ${{ env.INTEGRATION_COVERAGE_THRESHOLD }} \
            --badge integration-coverage-badge.json \
            --type "Integration Tests"
        else
          echo "‚ö†Ô∏è No integration coverage files found"
          echo '<?xml version="1.0" ?><coverage line-rate="0.0" lines-covered="0" lines-valid="1"/>' > integration-coverage-final.xml
        fi

    - name: Generate coverage summary
      working-directory: test-results
      run: |
        # Use external Python script to generate coverage summary
        unit_file=""
        integration_file=""

        [ -f "unit-coverage-final.xml" ] && unit_file="--unit-file unit-coverage-final.xml"
        [ -f "integration-coverage-final.xml" ] && integration_file="--integration-file integration-coverage-final.xml"

        # Run coverage summary script and capture environment variables
        summary_output=$(python ${{ github.workspace }}/.github/scripts/coverage_summary.py \
          $unit_file --unit-threshold ${{ env.UNIT_COVERAGE_THRESHOLD }} \
          $integration_file --integration-threshold ${{ env.INTEGRATION_COVERAGE_THRESHOLD }})

        # Display the summary
        echo "$summary_output"

        # Extract and set environment variables
        if echo "$summary_output" | grep -q "UNIT_COVERAGE_PASS="; then
          unit_pass=$(echo "$summary_output" | grep "UNIT_COVERAGE_PASS=" | cut -d'=' -f2)
          echo "UNIT_COVERAGE_PASS=$unit_pass" >> $GITHUB_ENV
        fi

        if echo "$summary_output" | grep -q "INTEGRATION_COVERAGE_PASS="; then
          integration_pass=$(echo "$summary_output" | grep "INTEGRATION_COVERAGE_PASS=" | cut -d'=' -f2)
          echo "INTEGRATION_COVERAGE_PASS=$integration_pass" >> $GITHUB_ENV
        fi

    - name: Upload coverage reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: coverage-reports
        path: |
          test-results/unit-coverage-final.xml
          test-results/integration-coverage-final.xml
          test-results/unit-coverage-badge.json
          test-results/integration-coverage-badge.json

    - name: Commit coverage badges
      if: github.ref == 'refs/heads/main'
      working-directory: test-results
      run: |
        # Configure git
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

        # Copy badge files to root and commit
        mkdir -p ${{ github.workspace }}/.github/badges
        [ -f unit-coverage-badge.json ] && cp unit-coverage-badge.json ${{ github.workspace }}/.github/badges/
        [ -f integration-coverage-badge.json ] && cp integration-coverage-badge.json ${{ github.workspace }}/.github/badges/

        cd ${{ github.workspace }}
        git add .github/badges/*.json

        # Only commit if there are changes
        if ! git diff --cached --quiet; then
          git commit -m "chore: update coverage badges [skip ci]

          ü§ñ Generated with Claude Code

          Co-Authored-By: Claude <noreply@anthropic.com>"
          git push
        else
          echo "No badge changes to commit"
        fi

  # =========================================
  # Security Scan
  # =========================================
  security:
    name: üîí Security Scan
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.package-changed == 'true'

    permissions:
      actions: read
      contents: read
      security-events: write

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: ${{ env.PACKAGE_PATH }}
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy results to GitHub Security
      if: always()
      uses: github/codeql-action/upload-sarif@v3
      continue-on-error: true
      with:
        sarif_file: 'trivy-results.sarif'
        category: 'trivy-security-scan'

    - name: Generate security summary
      if: always()
      run: |
        python ${{ github.workspace }}/.github/scripts/security_scan_summary.py \
          trivy-results.sarif || echo "Security scan completed"

    - name: Dependency vulnerability check
      working-directory: ${{ env.PACKAGE_PATH }}
      run: |
        pip install safety
        python ${{ github.workspace }}/.github/scripts/dependency_parser.py \
          pyproject.toml temp-requirements.txt || echo "Could not parse dependencies"

        if [ -f temp-requirements.txt ]; then
          safety check -r temp-requirements.txt || echo "‚ö†Ô∏è Vulnerabilities found"
          rm temp-requirements.txt
        fi

  # =========================================
  # Final Quality Gate
  # =========================================
  quality-gate:
    name: üö¶ Quality Gate
    runs-on: ubuntu-latest
    needs: [quality, unit-tests, integration-tests, coverage, security]
    if: always() && needs.setup.outputs.package-changed == 'true'

    steps:
    - name: Quality gate decision
      run: |
        echo "üö¶ Quality Gate Decision..."

        # Check results
        quality_result="${{ needs.quality.result }}"
        unit_result="${{ needs.unit-tests.result }}"
        integration_result="${{ needs.integration-tests.result }}"
        coverage_result="${{ needs.coverage.result }}"
        security_result="${{ needs.security.result }}"

        echo "üìä Results:"
        echo "‚Ä¢ Code Quality: $quality_result"
        echo "‚Ä¢ Unit Tests: $unit_result"
        echo "‚Ä¢ Integration Tests: $integration_result"
        echo "‚Ä¢ Coverage: $coverage_result"
        echo "‚Ä¢ Security: $security_result"

        # Determine overall result
        failed_gates=""
        [ "$quality_result" = "failure" ] && failed_gates="$failed_gates quality"
        [ "$unit_result" = "failure" ] && failed_gates="$failed_gates unit-tests"
        [ "$integration_result" = "failure" ] && failed_gates="$failed_gates integration-tests"
        [ "$coverage_result" = "failure" ] && failed_gates="$failed_gates coverage"
        [ "$security_result" = "failure" ] && failed_gates="$failed_gates security"

        if [ -n "$failed_gates" ]; then
          echo "‚ùå QUALITY GATE FAILED"
          echo "Failed gates:$failed_gates"
          echo "::error title=Quality Gate Failed::Failed gates:$failed_gates"
          exit 1
        else
          echo "‚úÖ QUALITY GATE PASSED"
          echo "::notice title=Quality Gate Success::All checks passed!"
        fi
