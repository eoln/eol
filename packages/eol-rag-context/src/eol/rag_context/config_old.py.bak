"""
Configuration for EOL RAG Context MCP Server.
"""

from typing import Optional, Dict, Any, List
from pydantic_settings import BaseSettings
from pydantic import Field, field_validator, ConfigDict
from pathlib import Path


class RedisConfig(BaseSettings):
    """Redis connection configuration."""
    model_config = ConfigDict(env_prefix="REDIS_")

    host: str = Field(default="localhost")
    port: int = Field(default=6379, env="REDIS_PORT")
    db: int = Field(default=0, env="REDIS_DB")
    password: Optional[str] = Field(default=None, env="REDIS_PASSWORD")
    decode_responses: bool = False  # Keep False for binary vector data
    max_connections: int = Field(default=50, env="REDIS_MAX_CONNECTIONS")
    socket_keepalive: bool = True
    socket_keepalive_options: Dict[int, int] = Field(default_factory=lambda: {
        1: 1,  # TCP_KEEPIDLE
        2: 3,  # TCP_KEEPINTVL
        3: 5,  # TCP_KEEPCNT
    })

    @property
    def url(self) -> str:
        """Generate Redis URL from components."""
        auth = f":{self.password}@" if self.password else ""
        return f"redis://{auth}{self.host}:{self.port}/{self.db}"

    class Config:
        env_prefix = "REDIS_"


class EmbeddingConfig(BaseSettings):
    """Embedding model configuration."""

    provider: str = Field(default="sentence-transformers", env="EMBEDDING_PROVIDER")
    model_name: str = Field(default="all-MiniLM-L6-v2", env="EMBEDDING_MODEL")
    dimension: int = Field(default=384, env="EMBEDDING_DIM")
    batch_size: int = Field(default=32, env="EMBEDDING_BATCH_SIZE")
    normalize: bool = Field(default=True, env="EMBEDDING_NORMALIZE")

    # Provider-specific configs
    openai_api_key: Optional[str] = Field(default=None, env="OPENAI_API_KEY")
    openai_model: str = Field(default="text-embedding-3-small", env="OPENAI_EMBEDDING_MODEL")

    @field_validator("dimension")
    @classmethod
    def validate_dimension(cls, v, info):
        """Validate embedding dimension matches model."""
        provider = info.data.get("provider", "sentence-transformers") if hasattr(info, 'data') else "sentence-transformers"
        model = info.data.get("model_name", "") if hasattr(info, 'data') else ""

        # Known model dimensions
        model_dims = {
            "all-MiniLM-L6-v2": 384,
            "all-mpnet-base-v2": 768,
            "text-embedding-3-small": 1536,
            "text-embedding-3-large": 3072,
        }

        if model in model_dims and v != model_dims[model]:
            return model_dims[model]
        return v

    class Config:
        env_prefix = "EMBEDDING_"


class IndexConfig(BaseSettings):
    """Vector index configuration."""

    # Index parameters
    index_name: str = Field(default="eol_context", env="INDEX_NAME")
    prefix: str = Field(default="doc:", env="INDEX_PREFIX")

    # HNSW parameters
    algorithm: str = Field(default="HNSW", env="INDEX_ALGORITHM")
    distance_metric: str = Field(default="COSINE", env="INDEX_DISTANCE_METRIC")
    initial_cap: int = Field(default=10000, env="INDEX_INITIAL_CAP")
    m: int = Field(default=16, env="INDEX_M")  # Number of bi-directional links
    ef_construction: int = Field(default=200, env="INDEX_EF_CONSTRUCTION")
    ef_runtime: int = Field(default=10, env="INDEX_EF_RUNTIME")

    # Hierarchical levels
    hierarchy_levels: int = Field(default=3, env="HIERARCHY_LEVELS")
    concept_prefix: str = Field(default="concept:", env="CONCEPT_PREFIX")
    section_prefix: str = Field(default="section:", env="SECTION_PREFIX")
    chunk_prefix: str = Field(default="chunk:", env="CHUNK_PREFIX")

    class Config:
        env_prefix = "INDEX_"


class ChunkingConfig(BaseSettings):
    """Document chunking configuration."""

    # Chunk sizes (in tokens)
    min_chunk_size: int = Field(default=100, env="MIN_CHUNK_SIZE")
    max_chunk_size: int = Field(default=512, env="MAX_CHUNK_SIZE")
    chunk_overlap: int = Field(default=64, env="CHUNK_OVERLAP")

    # Semantic chunking
    use_semantic_chunking: bool = Field(default=True, env="USE_SEMANTIC_CHUNKING")
    semantic_threshold: float = Field(default=0.7, env="SEMANTIC_THRESHOLD")

    # Code chunking
    code_chunk_by_function: bool = Field(default=True, env="CODE_CHUNK_BY_FUNCTION")
    code_max_lines: int = Field(default=100, env="CODE_MAX_LINES")

    # Document-specific settings
    respect_document_structure: bool = Field(default=True, env="RESPECT_DOC_STRUCTURE")
    markdown_split_headers: bool = Field(default=True, env="MARKDOWN_SPLIT_HEADERS")

    class Config:
        env_prefix = "CHUNK_"


class CacheConfig(BaseSettings):
    """Semantic caching configuration."""

    enabled: bool = Field(default=True, env="CACHE_ENABLED")
    ttl_seconds: int = Field(default=3600, env="CACHE_TTL")
    similarity_threshold: float = Field(default=0.97, env="CACHE_SIMILARITY_THRESHOLD")
    max_cache_size: int = Field(default=1000, env="CACHE_MAX_SIZE")

    # Cache hit rate optimization
    target_hit_rate: float = Field(default=0.31, env="CACHE_TARGET_HIT_RATE")
    adaptive_threshold: bool = Field(default=True, env="CACHE_ADAPTIVE_THRESHOLD")

    class Config:
        env_prefix = "CACHE_"


class ContextConfig(BaseSettings):
    """Context composition configuration."""

    # Token limits
    max_context_tokens: int = Field(default=32000, env="MAX_CONTEXT_TOKENS")
    reserve_tokens_for_response: int = Field(default=4000, env="RESERVE_TOKENS")

    # Retrieval parameters
    default_top_k: int = Field(default=10, env="DEFAULT_TOP_K")
    min_relevance_score: float = Field(default=0.7, env="MIN_RELEVANCE_SCORE")

    # Context strategy
    use_hierarchical_retrieval: bool = Field(default=True, env="USE_HIERARCHICAL")
    progressive_loading: bool = Field(default=True, env="PROGRESSIVE_LOADING")

    # Quality filters
    remove_redundancy: bool = Field(default=True, env="REMOVE_REDUNDANCY")
    redundancy_threshold: float = Field(default=0.9, env="REDUNDANCY_THRESHOLD")

    class Config:
        env_prefix = "CONTEXT_"


class DocumentConfig(BaseSettings):
    """Document processing configuration."""

    # Supported file patterns
    file_patterns: List[str] = Field(
        default_factory=lambda: [
            "*.md", "*.txt", "*.json", "*.yaml", "*.yml",
            "*.py", "*.js", "*.ts", "*.jsx", "*.tsx",
            "*.java", "*.go", "*.rs", "*.cpp", "*.c",
            "*.pdf", "*.docx", "*.doc",
        ],
        env="FILE_PATTERNS"
    )

    # Processing options
    extract_metadata: bool = Field(default=True, env="EXTRACT_METADATA")
    detect_language: bool = Field(default=True, env="DETECT_LANGUAGE")
    parse_code_structure: bool = Field(default=True, env="PARSE_CODE_STRUCTURE")

    # Size limits
    max_file_size_mb: int = Field(default=100, env="MAX_FILE_SIZE_MB")
    skip_binary_files: bool = Field(default=True, env="SKIP_BINARY_FILES")

    class Config:
        env_prefix = "DOC_"


class RAGConfig(BaseSettings):
    """Main RAG configuration aggregating all sub-configs."""

    # Sub-configurations
    redis: RedisConfig = Field(default_factory=RedisConfig)
    embedding: EmbeddingConfig = Field(default_factory=EmbeddingConfig)
    index: IndexConfig = Field(default_factory=IndexConfig)
    chunking: ChunkingConfig = Field(default_factory=ChunkingConfig)
    cache: CacheConfig = Field(default_factory=CacheConfig)
    context: ContextConfig = Field(default_factory=ContextConfig)
    document: DocumentConfig = Field(default_factory=DocumentConfig)

    # Server settings
    server_name: str = Field(default="eol-rag-context", env="SERVER_NAME")
    server_version: str = Field(default="0.1.0", env="SERVER_VERSION")
    debug: bool = Field(default=False, env="DEBUG")

    # Storage paths
    data_dir: Path = Field(default=Path("./data"), env="DATA_DIR")
    index_dir: Path = Field(default=Path("./indexes"), env="INDEX_DIR")

    @field_validator("data_dir", "index_dir")
    @classmethod
    def create_directories(cls, v):
        """Ensure directories exist."""
        v.mkdir(parents=True, exist_ok=True)
        return v

    class Config:
        env_prefix = "RAG_"
        env_file = ".env"
        env_file_encoding = "utf-8"

    @classmethod
    def from_file(cls, config_path: Path) -> "RAGConfig":
        """Load configuration from file."""
        import json
        import yaml

        if config_path.suffix == ".json":
            with open(config_path) as f:
                data = json.load(f)
        elif config_path.suffix in [".yaml", ".yml"]:
            with open(config_path) as f:
                data = yaml.safe_load(f)
        else:
            raise ValueError(f"Unsupported config format: {config_path.suffix}")

        return cls(**data)
